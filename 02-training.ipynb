{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### referenced by - https://github.com/kuleshov/audio-super-res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training ASR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.sys.path.append(os.path.abspath('.'))\n",
    "os.sys.path.append(os.path.dirname(os.path.abspath('.')))\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from asr_model import ASRNet, default_opt\n",
    "from io_utils import upsample_wav\n",
    "from io_utils import load_h5\n",
    "import tensorflow as tf\n",
    "#matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.0\n"
     ]
    }
   ],
   "source": [
    "args = {\n",
    "    'train'      : 'prep_audioset.h5',\n",
    "    'val'        : 'prep_audioset.val.h5',\n",
    "    'alg'        : 'adam',\n",
    "    'epochs'     : 5,\n",
    "    'logname'    : 'default_log_name',\n",
    "    'layers'     : 4,\n",
    "    'lr'         : 1e-3,\n",
    "    'batch_size' : 4\n",
    "}\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of arrays in input file: KeysView(<HDF5 file \"prep_audioset.h5\" (mode r)>)\n",
      "Shape of X: (48, 8192, 1)\n",
      "Shape of Y: (48, 8192, 1)\n",
      "List of arrays in input file: KeysView(<HDF5 file \"prep_audioset.val.h5\" (mode r)>)\n",
      "Shape of X: (48, 8192, 1)\n",
      "Shape of Y: (48, 8192, 1)\n"
     ]
    }
   ],
   "source": [
    "# get data\n",
    "X_train, Y_train = load_h5(args['train'])\n",
    "X_val, Y_val = load_h5(args['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of dimension: 8192\n",
      "number of channel: 1\n",
      "r: 1.0\n"
     ]
    }
   ],
   "source": [
    "# determine super-resolution level\n",
    "n_dim, n_chan = Y_train[0].shape\n",
    "print('number of dimension:',n_dim)\n",
    "print('number of channel:',n_chan)\n",
    "r = Y_train[0].shape[1] / X_train[0].shape[1]\n",
    "print('r:',r)\n",
    "assert n_chan == 1 # if not number of channel is not 0 -> Error assert!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Generator Model init...\n",
      "D-Block >>  Tensor(\"generator/Relu:0\", shape=(?, ?, 12), dtype=float32)\n",
      "D-Block >>  Tensor(\"generator/Relu_1:0\", shape=(?, ?, 24), dtype=float32)\n",
      "D-Block >>  Tensor(\"generator/Relu_2:0\", shape=(?, ?, 48), dtype=float32)\n",
      "D-Block >>  Tensor(\"generator/Relu_3:0\", shape=(?, ?, 48), dtype=float32)\n",
      "B-Block >>  Tensor(\"generator/Relu_4:0\", shape=(?, ?, 48), dtype=float32)\n",
      "U-Block >>  Tensor(\"generator/concat:0\", shape=(?, ?, 96), dtype=float32)\n",
      "U-Block >>  Tensor(\"generator/concat_1:0\", shape=(?, ?, 96), dtype=float32)\n",
      "U-Block >>  Tensor(\"generator/concat_2:0\", shape=(?, ?, 48), dtype=float32)\n",
      "U-Block >>  Tensor(\"generator/concat_3:0\", shape=(?, ?, 24), dtype=float32)\n",
      "Fin-Layer >>  Tensor(\"generator/Add:0\", shape=(?, ?, 1), dtype=float32)\n",
      ">> ...finish\n",
      "\n",
      "creating train_op with params: {'layers': 4, 'b1': 0.9, 'b2': 0.999, 'batch_size': 4, 'lr': 0.001, 'alg': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "def get_model(args, n_dim, r, from_ckpt=False, train=True):\n",
    "    \"\"\"Create a model based on arguments\"\"\"\n",
    "    \n",
    "    if train:\n",
    "        opt_params = {\n",
    "            'alg' : args['alg'], \n",
    "            'lr' : args['lr'], \n",
    "            'b1' : 0.9, \n",
    "            'b2' : 0.999,\n",
    "            'batch_size': args['batch_size'], \n",
    "            'layers': args['layers']}\n",
    "    else: \n",
    "        opt_params = default_opt\n",
    "\n",
    "    # create model & init\n",
    "    model = ASRNet(\n",
    "        from_ckpt=from_ckpt, \n",
    "        n_dim=n_dim, \n",
    "        r=r,\n",
    "        opt_params=opt_params, \n",
    "        log_prefix=args['logname'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = get_model(args, n_dim, r, from_ckpt=False, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training epoch (n:5)\n",
      "num-of-batch: 4\n",
      "\n",
      "Epoch 1 of 5 took 2.305s (12 minibatches)\n",
      "  training l2_loss/segsnr:\t\t0.053736\t5.767480\n",
      "  validation l2_loss/segsnr:\t\t0.053736\t5.767480\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Epoch 2 of 5 took 1.905s (12 minibatches)\n",
      "  training l2_loss/segsnr:\t\t0.053736\t5.767480\n",
      "  validation l2_loss/segsnr:\t\t0.053736\t5.767480\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Epoch 3 of 5 took 1.839s (12 minibatches)\n",
      "  training l2_loss/segsnr:\t\t0.053736\t5.767480\n",
      "  validation l2_loss/segsnr:\t\t0.053736\t5.767480\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Epoch 4 of 5 took 1.816s (12 minibatches)\n",
      "  training l2_loss/segsnr:\t\t0.053736\t5.767480\n",
      "  validation l2_loss/segsnr:\t\t0.053736\t5.767480\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Epoch 5 of 5 took 1.754s (12 minibatches)\n",
      "  training l2_loss/segsnr:\t\t0.053736\t5.767480\n",
      "  validation l2_loss/segsnr:\t\t0.053736\t5.767480\n",
      "-----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "model.fit(X_train, Y_train, X_val, Y_val, n_epoch=args['epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
