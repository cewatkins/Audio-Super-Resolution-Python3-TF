{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### referenced by - https://github.com/kuleshov/audio-super-res\n",
    "* 아래 audio-super-res로 명시된것은 위의 참고자료 모델을 의미함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 학습에 사용될 원본 wav파일들을 사용하여 학습용 h5포맷 데이터 생성하기 \n",
    "* ./data/train 폴더에 학습용 wav파일 원본들을 저장한다\n",
    "* ./data/train.txt에 학습용 wav파일의 목록을 저장한다\n",
    "* 전처리 과정에서 low-res와 high-res버전의 데이터를 생성하고 이를 h5포맷으로 저장한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, argparse\n",
    "import numpy as np\n",
    "import h5py\n",
    "import librosa\n",
    "from scipy import interpolate\n",
    "from scipy.signal import decimate\n",
    "from scipy.signal import butter, lfilter\n",
    "args = {\n",
    "    'interpolate'               : 0, # False\n",
    "    'dimension'                 : 8192 * 4, # dimension of patches\n",
    "    'stride'                    : 8192 * 2, # stride of patches\n",
    "    'scale'                     : 6, \n",
    "    'batch_size'                : 1,\n",
    "    'sr'                        : 16000,# sampling rate\n",
    "    'sam'                       : 1,\n",
    "    'train_out'                 : 'train.h5',\n",
    "    'train_in_dir'              : './data/train/',\n",
    "    'valid_out'                 : 'valid.h5',\n",
    "    'valid_in_dir'              : './data/valid/',\n",
    "    'train_file_list'           : './data/train.txt',\n",
    "    'valid_file_list'           : './data/valid.txt',\n",
    "    'temp_out'                  : 'temp.h5',\n",
    "    'temp_in_dir'               : './data/temp/',\n",
    "    'temp_file_list'            : './data/temp.txt'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def upsample(x_lr, r):\n",
    "    x_lr = x_lr.flatten()\n",
    "    x_hr_len = len(x_lr) * r\n",
    "    x_sp = np.zeros(x_hr_len)\n",
    "\n",
    "    i_lr = np.arange(x_hr_len, step=r)\n",
    "    i_hr = np.arange(x_hr_len)\n",
    "\n",
    "    f = interpolate.splrep(i_lr, x_lr)\n",
    "\n",
    "    x_sp = interpolate.splev(i_hr, f)\n",
    "\n",
    "    return x_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_data_preprocessed(h5_file, inputfiles, in_dir, args, save_examples=False):\n",
    "    \n",
    "    # 1) read original dataset\n",
    "    \n",
    "    file_list = []\n",
    "    file_extensions = set(['.wav'])\n",
    "    with open(inputfiles) as f:\n",
    "        for line in f:\n",
    "            filename = line.strip()\n",
    "            ext = os.path.splitext(filename)[1]\n",
    "            if ext in file_extensions:\n",
    "                file_list.append(os.path.join(in_dir, filename))\n",
    "                \n",
    "    num_files = len(file_list)\n",
    "    \n",
    "    # 2) read wav file (we always use interpolate mode) \n",
    "    # 3) create low-res version\n",
    "    # 4) upsample low-res version for same data size\n",
    "    # 5) patch the data\n",
    "    \n",
    "    d, d_lr = args['dimension'], (args['dimension'])\n",
    "    s, s_lr = args['stride'], (args['stride'])\n",
    "    hr_patches = list()\n",
    "    lr_patches = list()\n",
    "    for j, file_path in enumerate(file_list):\n",
    "        if j % 10 == 0: print('%d/%d' % (j, num_files))\n",
    "        \n",
    "        # load audio file\n",
    "        x, fs = librosa.load(file_path, sr=args['sr']) # sr = sample rates\n",
    "        \n",
    "        # crop so that it works with scailing ratio\n",
    "        x_len = len(x)\n",
    "        x = x[ : x_len - (x_len % args['scale'])]\n",
    "        \n",
    "        # generate low-res version\n",
    "        x_lr = decimate(x, args['scale'])\n",
    "        \n",
    "        #  upsample data(we will use preprocessed low-res data)\n",
    "        #  EX. scale x4 on dimension\n",
    "        #  data (low-res )2048 ---> [cubic-upscaling] --> 8192 ---> model input (8192)\n",
    "        #  label (high-res)8192 -----------------------------------> model output(8192)\n",
    "        x_lr = upsample(x_lr, args['scale'])\n",
    "        \n",
    "        assert len(x) % args['scale'] == 0\n",
    "        assert len(x_lr) == (len(x))\n",
    "        \n",
    "        # Generate patches\n",
    "        max_i = len(x) - d + 1 # d = dimension\n",
    "        for i in range(0, max_i, s): # s = strides \n",
    "            # keep only a fraction of all the patches\n",
    "            u = np.random.uniform()\n",
    "            if u > args['sam']: continue\n",
    "            \n",
    "            i_lr = i\n",
    "            \n",
    "            hr_patch = np.array( x[i : i+d] )\n",
    "            lr_patch = np.array( x_lr[i_lr : i_lr + d_lr] )    \n",
    "            assert len(hr_patch) == d\n",
    "            assert len(lr_patch) == d_lr\n",
    "            \n",
    "            hr_patches.append(hr_patch.reshape((d,1)))\n",
    "            lr_patches.append(lr_patch.reshape((d_lr,1)))\n",
    "    \n",
    "    \n",
    "    # 6) save as .h5 files    \n",
    "    # crop # of patches so that it's a multiple of mini-batch size\n",
    "    num_hr_patches = len(hr_patches)\n",
    "    num_lr_patches = len(lr_patches)\n",
    "    \n",
    "    print('num_hr_patches:', num_hr_patches)\n",
    "    print('num_lr_patches:', num_lr_patches)\n",
    "    print('batch_size:', args['batch_size'])\n",
    "    num_to_keep_hr = int(np.floor(num_hr_patches / args['batch_size']) * args['batch_size'])\n",
    "    hr_patches = np.array(hr_patches[:num_to_keep_hr])\n",
    "    \n",
    "    num_to_keep_lr = int(np.floor(num_lr_patches / args['batch_size']) * args['batch_size'])\n",
    "    lr_patches = np.array(lr_patches[:num_to_keep_lr])\n",
    "\n",
    "    if save_examples:\n",
    "        librosa.output.write_wav('example-hr.wav', hr_patches[40], fs, norm=False)\n",
    "        #librosa.output.write_wav('example-lr.wav', lr_patches[40], int(fs / args['scale']), norm=False)\n",
    "        librosa.output.write_wav('example-lr.wav', lr_patches[40], fs, norm=False)\n",
    "        print (hr_patches[40].shape)\n",
    "        print (lr_patches[40].shape)\n",
    "        print (hr_patches[40][0][:10])\n",
    "        print (lr_patches[40][0][:10])\n",
    "        print ('two examples saved')\n",
    "\n",
    "    print ('hr_patches shape:',hr_patches.shape)\n",
    "    print ('lr_patches shape:',lr_patches.shape)\n",
    "\n",
    "    # create the hdf5 file\n",
    "    data_set = h5_file.create_dataset('data', lr_patches.shape, np.float32) # lr\n",
    "    label_set = h5_file.create_dataset('label', hr_patches.shape, np.float32) # hr\n",
    "\n",
    "    data_set[...] = lr_patches\n",
    "    label_set[...] = hr_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/231\n",
      "10/231\n",
      "20/231\n",
      "30/231\n",
      "40/231\n",
      "50/231\n",
      "60/231\n",
      "70/231\n",
      "80/231\n",
      "90/231\n",
      "100/231\n",
      "110/231\n",
      "120/231\n",
      "130/231\n",
      "140/231\n",
      "150/231\n",
      "160/231\n",
      "170/231\n",
      "180/231\n",
      "190/231\n",
      "200/231\n",
      "210/231\n",
      "220/231\n",
      "230/231\n",
      "num_hr_patches: 621\n",
      "num_lr_patches: 621\n",
      "batch_size: 1\n",
      "(32768, 1)\n",
      "(32768, 1)\n",
      "[1.7370978e-05]\n",
      "[1.78091372e-05]\n",
      "two examples saved\n",
      "hr_patches shape: (621, 32768, 1)\n",
      "lr_patches shape: (621, 32768, 1)\n"
     ]
    }
   ],
   "source": [
    "# create train\n",
    "with h5py.File(args['train_out'], 'w') as f:\n",
    "    add_data_preprocessed(f, args['train_file_list'], args['train_in_dir'],args, save_examples=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 마찬가지로 검증 데이터셋도 h5파일로 구성한다\n",
    "* ./data/valid 폴더에 검증용 원본 데이터를 저장한다\n",
    "* ./data/valid.txt 파일에 검증용 데이터 목록을 저장한다\n",
    "* 1번과 같은 방식으로 h5파일 포맷으로 데이터를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/125\n",
      "10/125\n",
      "20/125\n",
      "30/125\n",
      "40/125\n",
      "50/125\n",
      "60/125\n",
      "70/125\n",
      "80/125\n",
      "90/125\n",
      "100/125\n",
      "110/125\n",
      "120/125\n",
      "num_hr_patches: 162\n",
      "num_lr_patches: 162\n",
      "batch_size: 1\n",
      "(32768, 1)\n",
      "(32768, 1)\n",
      "[-0.00555102]\n",
      "[-0.00548858]\n",
      "two examples saved\n",
      "hr_patches shape: (162, 32768, 1)\n",
      "lr_patches shape: (162, 32768, 1)\n"
     ]
    }
   ],
   "source": [
    "# create validation\n",
    "with h5py.File(args['valid_out'], 'w') as f:\n",
    "    add_data_preprocessed(f, args['valid_file_list'], args['valid_in_dir'],args, save_examples=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 기타 다른 데이터를 사용하기\n",
    "* ./data/temp 폴더에 원본 wav파일을 저장\n",
    "* ./data/temp.txt에 파일 리스트를 작성\n",
    "* 아래 코드를 실행하여 h5포맷으로 데이터를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_hr_patches: 0\n",
      "num_lr_patches: 0\n",
      "batch_size: 1\n",
      "hr_patches shape: (0,)\n",
      "lr_patches shape: (0,)\n"
     ]
    }
   ],
   "source": [
    "# create another set\n",
    "with h5py.File(args['temp_out'], 'w') as f:\n",
    "    add_data_preprocessed(f, args['temp_file_list'], args['temp_in_dir'], args, save_examples=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
